{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "A Python-based target-finder for a Rust-based classifier engine:\n",
        "This revised version:\n",
        "1. Properly handles frequency and uniqueness calculations\n",
        "2. Saves results to a JSON file instead of printing\n",
        "3. Includes input validation\n",
        "4. Adds error handling and logging\n",
        "5. Converts ngrams to UTF-8 byte patterns\n",
        "6. Includes metadata in the output\n",
        "\n",
        "The output JSON file will look something like:\n",
        "```json\n",
        "{\n",
        "  \"metadata\": {\n",
        "    \"min_frequency\": 2,\n",
        "    \"min_uniqueness\": 0.7,\n",
        "    \"ngram_range\": [1, 2]\n",
        "  },\n",
        "  \"targets\": {\n",
        "    \"class1\": {\n",
        "      \"label\": \"class1\",\n",
        "      \"targets\": [\n",
        "        {\n",
        "          \"text\": \"sample\",\n",
        "          \"weight\": 2.8,\n",
        "          \"frequency\": 4,\n",
        "          \"uniqueness\": 0.7,\n",
        "          \"bytes_pattern\": \"73616d706c65\"\n",
        "        },\n",
        "        ...\n",
        "      ]\n",
        "    },\n",
        "    \"class2\": {\n",
        "      ...\n",
        "    }\n",
        "  }\n",
        "}\n",
        "```\n",
        "\"\"\"\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import Dict, List, Tuple\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import KFold\n",
        "import json\n",
        "import logging\n",
        "from pathlib import Path\n",
        "\n",
        "@dataclass\n",
        "class NGramTarget:\n",
        "    text: str\n",
        "    weight: float\n",
        "    frequency: int\n",
        "    uniqueness: float\n",
        "    bytes_pattern: bytes = None  # UTF-8 bytes representation\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            'text': self.text,\n",
        "            'weight': float(self.weight),  # Convert numpy types to native\n",
        "            'frequency': int(self.frequency),\n",
        "            'uniqueness': float(self.uniqueness),\n",
        "            'bytes_pattern': self.bytes_pattern.hex() if self.bytes_pattern else None\n",
        "        }\n",
        "\n",
        "@dataclass\n",
        "class LabelTargets:\n",
        "    label: str\n",
        "    targets: List[NGramTarget]\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\n",
        "            'label': self.label,\n",
        "            'targets': [t.to_dict() for t in self.targets]\n",
        "        }\n",
        "\n",
        "class NGramTargetFinder:\n",
        "    def __init__(\n",
        "        self,\n",
        "        min_frequency: int = 3,\n",
        "        min_uniqueness: float = 0.8,\n",
        "        ngram_range: Tuple[int,int] = (1,3),\n",
        "        n_folds: int = 5,\n",
        "        output_path: Path = Path('ngram_targets')\n",
        "    ):\n",
        "        self.min_frequency = min_frequency\n",
        "        self.min_uniqueness = min_uniqueness\n",
        "        self.ngram_range = ngram_range\n",
        "        self.n_folds = n_folds\n",
        "        self.output_path = output_path\n",
        "        self.output_path.mkdir(exist_ok=True)\n",
        "\n",
        "        logging.basicConfig(level=logging.INFO)\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def find_and_save_targets(\n",
        "        self,\n",
        "        documents: List[str],\n",
        "        labels: List[str],\n",
        "        output_name: str\n",
        "    ) -> bool:\n",
        "        \"\"\"Main method to find targets and save results\"\"\"\n",
        "        try:\n",
        "            if not self._validate_inputs(documents, labels):\n",
        "                return False\n",
        "\n",
        "            targets = self.find_targets(documents, labels)\n",
        "            if not targets:\n",
        "                self.logger.error(\"No targets found\")\n",
        "                return False\n",
        "\n",
        "            self._save_targets(targets, output_name)\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in find_and_save_targets: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def _validate_inputs(self, documents: List[str], labels: List[str]) -> bool:\n",
        "        \"\"\"Validate input data\"\"\"\n",
        "        if not documents or not labels:\n",
        "            self.logger.error(\"Empty documents or labels\")\n",
        "            return False\n",
        "        if len(documents) != len(labels):\n",
        "            self.logger.error(\"Mismatched documents and labels lengths\")\n",
        "            return False\n",
        "        if len(set(labels)) < 2:\n",
        "            self.logger.error(\"Need at least two different labels\")\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def find_targets(\n",
        "        self,\n",
        "        documents: List[str],\n",
        "        labels: List[str]\n",
        "    ) -> Dict[str, LabelTargets]:\n",
        "        \"\"\"Find ngram targets for each label\"\"\"\n",
        "        try:\n",
        "            vectorizer = CountVectorizer(ngram_range=self.ngram_range)\n",
        "            X = vectorizer.fit_transform(documents)\n",
        "            ngrams = vectorizer.get_feature_names_out()\n",
        "\n",
        "            # Calculate base frequencies for all labels\n",
        "            label_frequencies = self._calculate_base_frequencies(X, labels, ngrams)\n",
        "\n",
        "            # Calculate uniqueness scores\n",
        "            label_targets = self._calculate_targets(label_frequencies, ngrams)\n",
        "\n",
        "            return label_targets\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in find_targets: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def _calculate_base_frequencies(\n",
        "        self,\n",
        "        X,\n",
        "        labels: List[str],\n",
        "        ngrams: List[str]\n",
        "    ) -> Dict[str, Dict[str, int]]:\n",
        "        \"\"\"Calculate raw frequencies for each label\"\"\"\n",
        "        frequencies = {}\n",
        "        for label in set(labels):\n",
        "            label_mask = np.array(labels) == label\n",
        "            label_docs = X[label_mask]\n",
        "            frequencies[label] = {\n",
        "                ngram: int(freq)\n",
        "                for ngram, freq in zip(ngrams, label_docs.sum(axis=0).A1)\n",
        "            }\n",
        "        return frequencies\n",
        "\n",
        "    def _calculate_targets(\n",
        "        self,\n",
        "        label_frequencies: Dict[str, Dict[str, int]],\n",
        "        ngrams: List[str]\n",
        "    ) -> Dict[str, LabelTargets]:\n",
        "        \"\"\"Calculate final targets with scores\"\"\"\n",
        "        targets = {}\n",
        "\n",
        "        for label in label_frequencies:\n",
        "            ngram_targets = []\n",
        "            other_labels = set(label_frequencies.keys()) - {label}\n",
        "\n",
        "            for ngram in ngrams:\n",
        "                label_freq = label_frequencies[label].get(ngram, 0)\n",
        "                other_freq = max(\n",
        "                    label_frequencies[other_label].get(ngram, 0)\n",
        "                    for other_label in other_labels\n",
        "                )\n",
        "\n",
        "                if label_freq >= self.min_frequency:\n",
        "                    uniqueness = label_freq / (label_freq + other_freq) if (label_freq + other_freq) > 0 else 0\n",
        "                    if uniqueness >= self.min_uniqueness:\n",
        "                        ngram_targets.append(\n",
        "                            NGramTarget(\n",
        "                                text=ngram,\n",
        "                                weight=label_freq * uniqueness,\n",
        "                                frequency=label_freq,\n",
        "                                uniqueness=uniqueness,\n",
        "                                bytes_pattern=ngram.encode('utf-8')\n",
        "                            )\n",
        "                        )\n",
        "\n",
        "            if ngram_targets:\n",
        "                ngram_targets.sort(key=lambda x: x.weight, reverse=True)\n",
        "                targets[label] = LabelTargets(label=label, targets=ngram_targets)\n",
        "\n",
        "        return targets\n",
        "\n",
        "    def _save_targets(self, targets: Dict[str, LabelTargets], output_name: str):\n",
        "        \"\"\"Save targets to JSON file\"\"\"\n",
        "        output_file = self.output_path / f\"{output_name}.json\"\n",
        "\n",
        "        # Convert to serializable format\n",
        "        output_data = {\n",
        "            'metadata': {\n",
        "                'min_frequency': self.min_frequency,\n",
        "                'min_uniqueness': self.min_uniqueness,\n",
        "                'ngram_range': self.ngram_range\n",
        "            },\n",
        "            'targets': {\n",
        "                label: targets[label].to_dict()\n",
        "                for label in targets\n",
        "            }\n",
        "        }\n",
        "\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(output_data, f, indent=2)\n",
        "\n",
        "        self.logger.info(f\"Saved targets to {output_file}\")\n",
        "\n",
        "# Sample use:\n",
        "if __name__ == \"__main__\":\n",
        "    documents = [\n",
        "        \"this is a sample document\",\n",
        "        \"another example document\",\n",
        "        \"yet another document example\",\n",
        "        \"this is different\"\n",
        "    ] * 3  # Replicate for more samples\n",
        "\n",
        "    labels = [\"class1\", \"class2\", \"class2\", \"class1\"] * 3\n",
        "\n",
        "    finder = NGramTargetFinder(\n",
        "        min_frequency=2,\n",
        "        min_uniqueness=0.7,\n",
        "        ngram_range=(1,2)\n",
        "    )\n",
        "\n",
        "    success = finder.find_and_save_targets(\n",
        "        documents,\n",
        "        labels,\n",
        "        \"targets\"\n",
        "    )\n",
        "\n",
        "    if success:\n",
        "        print(\"Target finding completed successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqyniY8Mj4RR",
        "outputId": "09a89b44-ac0f-45e4-ed0e-d193a4189ee6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target finding completed successfully\n"
          ]
        }
      ]
    }
  ]
}